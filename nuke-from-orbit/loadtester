#!/usr/bin/env bash

# Set convenience variables
script_dir="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null 2>&1 && pwd )"
config_dir=${script_dir}/kubernetes-config
test_dir=${script_dir}/test_scripts
RED='\033[0;31m'
YELLOW='\033[1;33m'
GREEN='\033[0;32m'
NC='\033[0m'

# Check to make sure required programs are installed
universal_requirements_check() {
  if ! [[ -x "$(command -v gcloud)" ]]; then
    echo 'Error: gcloud is not installed. Please refer to https://cloud.google.com/sdk/install for instructions.' >&2
    exit 1
  fi

  if ! [[ -x "$(command -v jq)" ]]; then
    echo 'Error: jq is not installed. Please run  `sudo apt-get install jq` to install it and then try again.' >&2
    exit 1
  fi

  if ! [[ -x "$(command -v kubectl)" ]]; then
    echo 'Error: kubectl is not installed. Please run `gcloud components install kubectl` and try again.' >&2
    exit 1
  fi

  if ! [[ -x "$(command -v pipenv)" ]]; then
    echo 'Error: pipenv is not installed. Please refer to https://github.com/pypa/pipenv for instructions.' >&2
    exit 1
  fi


  if [[ -z "$PIPENV_ACTIVE" ]]; then
    echo 'Looks like your pipenv environment has not been activated. Please return to project root and run `pipenv shell` before proceeding. If you have not yet initialized your pipenv environment you will need to run `pipenv install --python 3.7 --ignore-pipfile` from the project root.' >&2
    exit 1
  fi
}

self_contained_requirements_check() {
  if ! [[ -x "$(command -v terraform)" ]]; then
    echo 'Error: terraform is not installed. Please refer to https://learn.hashicorp.com/terraform/getting-started/install.html for instructions.' >&2
    exit 1
  fi

  if ! [[ -x "$(command -v gzr)" ]]; then
    echo 'Error: gazer is not installed. Please ensure ruby is installed and run `gem install gazer`.' >&2
    exit 1
  fi
}

# Terraform functions
gke_cluster_deploy() {
  cd ${script_dir}/terraform/gke_loadtest_cluster
  terraform init
  terraform apply -auto-approve
  terraform output -json > output.json
  cd $script_dir
}

loadtest_dns_deploy() {
  cd ${script_dir}/terraform/aws_loadtest_dns
  terraform init
  terraform apply -auto-approve
  terraform output -json > output.json
  cd $script_dir
}

looker_deploy() {
  cd ${script_dir}/terraform/aws_looker_instance
  terraform init
  terraform apply -auto-approve
  terraform output -json > output.json
  cd $script_dir
}

gke_cluster_destroy() {
  cd ${script_dir}/terraform/gke_loadtest_cluster
  terraform destroy -auto-approve
  cd $script_dir
}

loadtest_dns_destroy() {
  cd ${script_dir}/terraform/aws_loadtest_dns
  terraform destroy -auto-approve
  cd $script_dir
}

looker_destroy() {
  cd ${script_dir}/terraform/aws_looker_instance
  terraform destroy -auto-approve
  cd $script_dir
}

# gcloud-only build functions
gke_loadtest_cluster_gcloud() {
  gcloud container clusters create $loadtest_name \
   --project $gcp_project_id \
   --zone $gcp_zone \
   --scopes "https://www.googleapis.com/auth/cloud-platform" \
   --num-nodes "$gcp_cluster_node_count" \
   --machine-type $gcp_cluster_machine_type \
   --release-channel regular
}

gke_loadtest_cluster_ip_gcloud() {
  gcloud compute addresses create ${loadtest_name} --global
  loadtest_ip_address=$(gcloud compute addresses describe  $loadtest_name --global --format json | jq -r '.address')
}

gke_loadtest_cluster_destroy_gcloud() {
  gcloud container clusters delete $loadtest_name --zone $gcp_zone --quiet
}

gke_loadtest_cluster_ip_destroy_gcloud() {
  gcloud compute addresses delete $loadtest_name --global --quiet
}

# Parse kubernetes jinja templates into proper config files
parse_config() {
  echo "Cleaning out any old configs"
  rm -f ${script_dir}/kubernetes-config/*.yaml
  echo "Parsing kubernetes config templates"
  if [[ -z $setup_command ]]
  then
    python ${script_dir}/kubernetes-config/parse_kube_templates.py --only-user-config --image-tag $image_tag
  else
    python ${script_dir}/kubernetes-config/parse_kube_templates.py --image-tag $image_tag
  fi
}

# Self-contained only: Provision Looker instance
provision_looker() {
  echo "Provisioning Looker instance"
  python ${script_dir}/looker-provisioning/looker_setup.py
  echo "Provisioning attempt complete."
}

# Parse relevant config file to set needed variables
set_variables() {

  # Set required args here
  required_args=(
    'gcp_project_id'
    'loadtest_name'
    'loadtest_dns_domain'
    'loadtest_step_load'
    'loadtest_worker_count'
    'loadtest_script_name'
    'gcp_oauth_client_id'
    'gcp_oauth_client_secret'
    'gcp_zone'
    'gcp_cluster_node_count'
    'gcp_cluster_machine_type'
  )

  # Set optional args here
  optional_args=(
    'looker_user'
    'looker_pass'
    'looker_api_client_id'
    'looker_api_client_secret'
  )

  # Set required args for self contained mode here
  required_self_contained_args=(
    'aws_access_key'
    'aws_secret_key'
    'lookml_project_repo'
  )

  # Set optional args for self contained mode here
  optional_self_contained_args=(
    'aws_session_token'
  )

  # Create an array of argument arrays to iterate through
  subgroups=('required_args' 'optional_args')
  if [[ $setup_command == 'self-contained' ]]
  then
    subgroups+=('required_self_contained_args' 'optional_self_contained_args')
  fi

  # Initialize arrays for errors and warnings
  errors=()
  warnings=()

  # Loop through array of arrays
  for group in "${subgroups[@]}"; do
    # set the type to either 'required' or 'optional'
    # used to determine if missing vals are errors or warnings
    type=$(echo $group | cut -f 1 -d '_')

    # set variable for nested array iteration
    declare -n lst="$group"

    # For each array set variables appropriately and append missing to errors or warnings
    for i in "${lst[@]}"; do
      val=$(cat $config_file | jq -r --arg i "$i" '.|.[$i] // empty' | tr -d '[:space:]')
      if [[ -z $val ]] && [[ $type == 'required' ]]
      then
        errors+=($i)
      elif [[ -z $val ]] && [[ $type == 'optional' ]]
      then
        warnings+=($i)
      else
        eval "$i=$val"
      fi
    done
  done

  # If there are any warnings print them
  if ! [[ -z $warnings ]]
  then
    printf "\n${YELLOW}Warning: Did not find entries for the following parameters. While these parameters are not required their absence may cause errors!${NC}\n"
    printf "${YELLOW}%s${NC}\n" "${warnings[@]}"
  fi

  # If there are any errors print them and crash out
  if ! [[ -z $errors ]]
  then
    printf "\n${RED}Error: Did not find entries for the following parameters. These values are required and must be present in order to continue!${NC}\n"
    printf "${RED}%s${NC}\n" "${errors[@]}"
    exit 1
  fi
}

# Build (or rebuild) the load test image
build_loadtest_image() {
  cp ${test_dir}/${loadtest_script_name}.py ${script_dir}/docker-image/locust-tasks/tasks.py
  gcloud builds submit --tag gcr.io/${gcp_project_id}/${loadtest_name}:${image_tag} docker-image/.
}

# Configure access to kubernetes cluster via gcloud
get_kubernetes_creds() {
  gcloud container clusters get-credentials $loadtest_name \
    --zone $gcp_zone \
    --project $gcp_project_id
}

# Set the oauth secret (used by iap)
set_oauth_secret() {
  kubectl create secret generic iap-secret \
    --from-literal=client_id=$gcp_oauth_client_id \
    --from-literal=client_secret=$gcp_oauth_client_secret
}

# Set the Looker username and password secret
# dry run trick is to handle updates in place
set_looker_secret() {
  if ! [[ -z $looker_user || -z $looker_pass ]]
  then
    kubectl create secret generic website-creds \
      --from-literal=username=$looker_user \
      --from-literal=password=$looker_pass \
      --dry-run=client \
      --save-config \
      -o yaml \
      | kubectl apply -f -
  fi
}

# Set the Looker API secret
# dry run trick is to handle updates in place
set_looker_api_secret() {
  if ! [[ -z $looker_api_client_id || -z $looker_api_client_secret ]]
  then
    kubectl create secret generic api-creds \
      --from-literal=client_id=$looker_api_client_id \
      --from-literal=client_secret=$looker_api_client_secret \
      --dry-run=client \
      --save-config \
      -o yaml \
      | kubectl apply -f -
  fi
}

# Self-contained only: Set AWS credentials for monitoring
set_aws_secret() {
  kubectl create secret generic aws-creds \
    --from-literal=aws-access-key=$aws_access_key \
    --from-literal=aws-secret-key=$aws_secret_key \
    --from-literal=aws-session-token=$aws_session_token
}

# Deploy GCP managed SSL certificate
deploy_managed_certificate() {
  kubectl apply -f ${config_dir}/loadtest-cert.yaml
}

# Backend config for establishing IAP authority over kubernetes resources
deploy_backend_config() {
  kubectl apply -f ${config_dir}/config-default.yaml
}

# Deploy the locust stack
deploy_locust() {
  kubectl apply -f ${config_dir}/locust-controller.yaml
  kubectl rollout status deployment/lm-pod
  kubectl apply -f ${config_dir}/locust-worker-controller.yaml
}

# Self-contained only: deploy cloudwatch monitoring stack
deploy_cloudwatch() {
  kubectl apply -f ${config_dir}/cloudwatch-config.yaml
  kubectl apply -f ${config_dir}/cloudwatch-controller.yaml
}

# Deploy prometheus
deploy_prometheus() {
  kubectl apply -f ${config_dir}/prometheus-config.yaml
  kubectl apply -f ${config_dir}/prometheus-controller.yaml
}

# Deploy grafana
deploy_grafana() {
  kubectl apply -f ${config_dir}/grafana-config.yaml
  kubectl apply -f ${config_dir}/grafana-controller.yaml
}

# Deploy ingress controller
deploy_ingress() {
  kubectl apply -f ${config_dir}/loadtest-ingress.yaml
}

# Set up IAP
set_iap_bindings() {
  for backend in $(gcloud compute backend-services list --format="value(name)")
  do
    echo "backend service: ${backend}"
    gcloud iap web add-iam-policy-binding \
      --member $gcp_iap_email \
      --role roles/iap.httpsResourceAccessor \
      --service $backend  \
      --resource-type backend-services
  done
}

# checks worker variable against available CPUs
check_worker_count() {
  cores=$(echo $gcp_cluster_machine_type | cut -f 3 -d '-')
  available_cpus=$(($cores * $gcp_cluster_node_count))
  if [[ $loadtest_worker_count -ge $available_cpus ]]
  then
    printf "\n${RED}Error: Requested worker count of ${loadtest_worker_count} exceeds cluster capacity of ${available_cpus}. Please increase available CPUs or request fewer workers.${NC}\n"
    exit 1
  fi
}

# Compares update tag to original tag
compare_tags() {
  current_tag=$(kubectl get deployment lw-pod -o json | jq -r '.spec.template.spec.containers[0].image' | cut -f 2 -d ':')
  if [[ $image_tag == 'latest' ]]
  then
    printf "\n${YELLOW}Warning: Use of latest tag detected. This will work just fine but you may want to consider using a unique tag with a version (e.g. v2, v3 etc).${NC}\n"
  elif [[ $image_tag != 'latest' && $current_tag == $image_tag ]]
  then
    printf "\n${RED}Error: Provided tag matches current tag. Please enter a unique tag.${NC}\n"
    exit 1
  else
    echo "Updating tag from ${current_tag} to ${image_tag}"
  fi
}

# Removes old workers and master to prevent resource contention and force correct rebuild
spin_down_locust() {
  echo "Spinning down locust deployments"
  kubectl delete deployment lw-pod
  kubectl delete deployment lm-pod
}

# Define aggregate functions
self_contained_setup() {
  echo "Self contained setup triggered"
  echo "This is an advanced setup mode and likely not what you want. Are you sure you want to proceed? (yes/no)"
  read confirm
  if [[ $confirm == 'yes' ]]
  then
    echo -n "self-contained" > ${script_dir}/.deploy_type
    config_file=${script_dir}/.self_contained_params.json
    self_contained_requirements_check
    gke_cluster_deploy
    loadtest_dns_deploy
    looker_deploy
    parse_config
    set_variables
    build_loadtest_image
    get_kubernetes_creds
    set_oauth_secret
    set_looker_secret
    set_looker_api_secret
    set_aws_secret
    deploy_managed_certificate
    deploy_backend_config
    deploy_locust
    deploy_cloudwatch
    deploy_prometheus
    deploy_grafana
    deploy_ingress
    provision_looker
  else
    echo "Aborting..."
  fi
}

external_setup() {
  echo "External setup triggered"
  echo -n "external" > ${script_dir}/.deploy_type
  config_file=${script_dir}/config.json
  set_variables
  check_worker_count
  gke_loadtest_cluster_gcloud
  gke_loadtest_cluster_ip_gcloud
  parse_config
  build_loadtest_image
  get_kubernetes_creds
  set_oauth_secret
  set_looker_secret
  set_looker_api_secret
  deploy_managed_certificate
  deploy_backend_config
  deploy_locust
  deploy_ingress
  printf "\n${GREEN}Cluster IP address is ${loadtest_ip_address}. Please create an A Record in your DNS provider for *.${loadtest_dns_domain} that points to ${loadtest_ip_address}.${NC}\n"
}

teardown() {
  deploy_type=$(cat ${script_dir}/.deploy_type)
  if [[ $deploy_type == 'self-contained' ]]
  then
    looker_destroy
    loadtest_dns_destroy
    gke_cluster_destroy
  else
    config_file=${script_dir}/config.json
    set_variables
    gke_loadtest_cluster_destroy_gcloud
    gke_loadtest_cluster_ip_destroy_gcloud
    printf "\n${YELLOW}Please delete the A Record for *.${loadtest_dns_domain} from your DNS provider!${NC}\n"
  fi
}

update_test() {
  config_file=${script_dir}/config.json
  compare_tags
  set_variables
  check_worker_count
  parse_config
  spin_down_locust
  build_loadtest_image
  set_looker_secret
  set_looker_api_secret
  deploy_locust
}

update_config() {
  config_file=${script_dir}/config.json
  set_variables
  check_worker_count
  parse_config
  spin_down_locust
  set_looker_secret
  set_looker_api_secret
  deploy_locust
}

print_help() {
  echo "Usage:"
  echo "    loadtester -h                             Display this help message."
  echo "    loadtester -v                             Display the version of the tool and exit."
  echo "    loadtester setup [self-contained]         Sets up the load tester. If self-contained is specified attempts advanced self-contained mode (not recommended)."
  echo "    loadtester update test -t <tag>|config  Updates either the test script or config. Updating the test will rebuild the containers versioned on the provided tag."
  echo "    loadtester teardown                       Tears down the load tester."
}

# Parse command input
universal_requirements_check
while getopts ":hv" opt; do
  case ${opt} in
    h)
      print_help
      exit 0
      ;;
    v)
      version=$(cat ${script_dir}/.version)
      echo $version
      exit 0
      ;;
    *)
      echo "Invalid Option: -$OPTARG" 1>&2
      print_help
      exit 1
      ;;
  esac
done
shift $((OPTIND -1))

subcommand=$1; shift
case "$subcommand" in
  setup)
    setup_command=$1; shift
    image_tag='v1'
    if ! [[ -z $setup_command ]]
    then
      case "$setup_command" in
        self-contained)
          self_contained_setup
          ;;
        *)
          echo "Invalid Option: $setup_command" 1>&2
          print_help
          exit 1
          ;;
      esac
    else
      external_setup
    fi
    ;;
  update)
    update_command=$1; shift
    case "$update_command" in
      config)
        image_tag=$(kubectl get deployment lw-pod -o json | jq -r '.spec.template.spec.containers[0].image' | cut -f 2 -d ':')
        update_config
        ;;
      test)
        while getopts ":t:" opt; do
          case ${opt} in
            t)
              image_tag=$OPTARG
              ;;
            \?)
              echo "Invalid Option: -$OPTARG" 1>&2
              exit 1
              ;;
          esac
        done
        shift $((OPTIND -1))
        if ! [[ -z $image_tag ]]
        then
          update_test
        else
          echo "Please provide a tag"
          print_help
          exit 1
        fi
        ;;
      *)
        echo "Invalid Option: $update_command" 1>&2
        exit 1
        ;;
    esac
    ;;
  teardown)
    teardown
    ;;
  *)
    echo "Invalid Option: $subcommand" 1>&2
    print_help
    exit 1
    ;;
  esac

exit 0
